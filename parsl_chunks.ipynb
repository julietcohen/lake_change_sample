{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsl workflow in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# visualization\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "# PDG packages\n",
    "import pdgstaging\n",
    "import pdgraster\n",
    "import py3dtiles\n",
    "import viz_3dtiles\n",
    "#from viz_3dtiles import TreeGenerator, BoundingVolumeRegion\n",
    "#import pdgpy3dtiles\n",
    "#from StagedTo3DConverter import StagedTo3DConverter\n",
    "\n",
    "# logging and configuration\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import logging.config\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "# Parsl\n",
    "import parsl\n",
    "from parsl import python_app\n",
    "from parsl.config import Config\n",
    "#from parsl.channels import LocalChannel\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.providers import LocalProvider\n",
    "#from parsl.executors.threads import ThreadPoolExecutor\n",
    "#from parsl.providers import LocalProvider\n",
    "#from parsl.providers import KubernetesProvider\n",
    "#from parsl.addresses import address_by_route\n",
    "#from kubernetes import client, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set configuration and data path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_config = '/home/jcohen/lake_change_sample/ingmar-config.json'\n",
    "logging_config = '/home/jcohen/lake_change_sample/logging.json'\n",
    "\n",
    "base_dir = Path('/home/pdg/data/nitze_lake_change/data_sample_2022-09-09')\n",
    "subdirs = ['32607', '32608', '32609']\n",
    "filename = 'lake_change.gpkg'\n",
    "# to define each .gpkg file within each UTM subdir as a string representation with forward slashes, use as_posix() for each iteration\n",
    "# of base_dir + filename. The ** represents that any subdir string can be present between the base_dir and the filename, meaning I do not\n",
    "# think that we needed to create the object subdirs above\n",
    "input = [p.as_posix() for p in base_dir.glob('**/' + filename)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to initialize parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x7f8089d41fc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " activate_env = 'conda activate pdgviz'\n",
    "\n",
    " htex_config = Config(\n",
    "   executors = [\n",
    "       HighThroughputExecutor(\n",
    "            max_workers = 32,\n",
    "            provider = LocalProvider(\n",
    "                worker_init = activate_env,\n",
    "                max_blocks = 1)\n",
    "       )\n",
    "   ]\n",
    " )\n",
    "\n",
    "parsl.clear()\n",
    "parsl.load(htex_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_parsl():\n",
    "#     parsl.set_stream_logger()\n",
    "#     #from parslexec import local_exec\n",
    "#     #from parslexec import htex_kube\n",
    "\n",
    "#     htex_kube = Config(\n",
    "#         executors=[\n",
    "#             HighThroughputExecutor(\n",
    "#                 label='kube-htex',\n",
    "#                 cores_per_worker=1,\n",
    "#                 max_workers=2,\n",
    "#                 worker_logdir_root='/',\n",
    "#                 # Address for the pod worker to connect back\n",
    "#                 # address=address_by_route(),\n",
    "#                 address='192.168.0.103',\n",
    "#                 # address_probe_timeout=3600,\n",
    "#                 worker_debug=True,\n",
    "#                 provider=KubernetesProvider(\n",
    "#                     namespace=\"test\",\n",
    "\n",
    "#                     # Docker image url to use for pods\n",
    "#                     image='mbjones/python3-parsl:0.2',\n",
    "\n",
    "#                     # Command to be run upon pod start, such as:\n",
    "#                     # 'module load Anaconda; source activate parsl_env'.\n",
    "#                     # or 'pip install parsl'\n",
    "#                     #worker_init='echo \"Worker started...\"; lf=`find . -name \\'manager.log\\'` tail -n+1 -f ${lf}',\n",
    "#                     worker_init='echo \"Worker started...\"',\n",
    "\n",
    "#                     # The secret key to download the image\n",
    "#                     # secret=\"YOUR_KUBE_SECRET\",\n",
    "\n",
    "#                     # Should follow the Kubernetes naming rules\n",
    "#                     pod_name='parsl-worker',\n",
    "\n",
    "#                     nodes_per_block=1,\n",
    "#                     init_blocks=2,\n",
    "#                     min_blocks=1,\n",
    "#                     # Maximum number of pods to scale up\n",
    "#                     max_blocks=4,\n",
    "#                 ),\n",
    "#             ),\n",
    "#         ]\n",
    "#     )\n",
    "#     # parsl.load(local_exec)\n",
    "#     parsl.load(htex_kube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicitly define StagedTo3DConverter class & its methods rather than sourcing it in (I believe this needs to be debugged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class StagedTo3DConverter():\n",
    "    \"\"\"\n",
    "        Processes staged vector data into Cesium 3D tiles according to the\n",
    "        settings in a config file or dict. This class acts as the orchestrator\n",
    "        of the other viz-3dtiles classes, and coordinates the sending and\n",
    "        receiving of information between them.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config\n",
    "    ):\n",
    "        \"\"\"\n",
    "            Initialize the StagedTo3DConverter class.\n",
    "            Parameters\n",
    "            ----------\n",
    "            config : dict or str\n",
    "                A dictionary of configuration settings or a path to a config\n",
    "                JSON file. (See help(pdgstaging.ConfigManager))\n",
    "        \"\"\"\n",
    "\n",
    "        self.config = pdgstaging.ConfigManager(config)\n",
    "        self.tiles = pdgstaging.TilePathManager(\n",
    "            **self.config.get_path_manager_config())\n",
    "\n",
    "    def all_staged_to_3dtiles(\n",
    "        self\n",
    "    ):\n",
    "        \"\"\"\n",
    "            Process all staged vector tiles into 3D tiles.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the list of staged vector tiles\n",
    "        paths = self.tiles.get_filenames_from_dir('staged')\n",
    "        # Process each tile\n",
    "        for path in paths:\n",
    "            self.staged_to_3dtile(path)\n",
    "\n",
    "    def staged_to_3dtile(self, path):\n",
    "        \"\"\"\n",
    "            Convert a staged vector tile into a B3DM tile file and a matching\n",
    "            JSON tileset file.\n",
    "            Parameters\n",
    "            ----------\n",
    "            path : str\n",
    "                The path to the staged vector tile.\n",
    "            Returns\n",
    "            -------\n",
    "            tile, tileset : Cesium3DTile, Tileset\n",
    "                The Cesium3DTiles and Cesium3DTileset objects\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Get information about the tile from the path\n",
    "            tile = self.tiles.tile_from_path(path)\n",
    "            out_path = self.tiles.path_from_tile(tile, '3dtiles')\n",
    "\n",
    "            tile_bv = self.bounding_region_for_tile(tile)\n",
    "\n",
    "            # Get the filename of the tile WITHOUT the extension\n",
    "            tile_filename = os.path.splitext(os.path.basename(out_path))[0]\n",
    "            # Get the base of the path, without the filename\n",
    "            tile_dir = os.path.dirname(out_path) + os.path.sep\n",
    "\n",
    "            # Log the event\n",
    "            logger.info(\n",
    "                f'Creating 3dtile from {path} for tile {tile} to {out_path}.')\n",
    "\n",
    "            # Read in the staged vector tile\n",
    "            gdf = gpd.read_file(path)\n",
    "\n",
    "            # Check if the gdf is empty\n",
    "            if len(gdf) == 0:\n",
    "                logger.warning(\n",
    "                    f'Vector tile {path} is empty. 3D tile will not be'\n",
    "                    ' created.')\n",
    "                return\n",
    "\n",
    "            # Remove polygons with centroids that are outside the tile boundary\n",
    "            prop_cent_in_tile = self.config.polygon_prop(\n",
    "                'centroid_within_tile')\n",
    "            gdf = gdf[gdf[prop_cent_in_tile]]\n",
    "\n",
    "            # Check if deduplication should be performed\n",
    "            dedup_here = self.config.deduplicate_at('3dtiles')\n",
    "            dedup_method = self.config.get_deduplication_method()\n",
    "\n",
    "            # Deduplicate if required\n",
    "            if dedup_here and (dedup_method is not None):\n",
    "                dedup_config = self.config.get_deduplication_config(gdf)\n",
    "                dedup = dedup_method(gdf, **dedup_config)\n",
    "                gdf = dedup['keep']\n",
    "\n",
    "                # The tile could theoretically be empty after deduplication\n",
    "                if len(gdf) == 0:\n",
    "                    logger.warning(\n",
    "                        f'Vector tile {path} is empty after deduplication.'\n",
    "                        ' 3D Tile will not be created.')\n",
    "                    return\n",
    "\n",
    "            # Create & save the b3dm file\n",
    "            ces_tile, ces_tileset = TreeGenerator.leaf_tile_from_gdf(\n",
    "                gdf,\n",
    "                dir=tile_dir,\n",
    "                filename=tile_filename,\n",
    "                z=self.config.get('z_coord'),\n",
    "                geometricError=self.config.get('geometricError'),\n",
    "                tilesetVersion=self.config.get('version'),\n",
    "                boundingVolume=tile_bv\n",
    "            )\n",
    "\n",
    "            return ces_tile, ces_tileset\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f'Error creating 3D Tile from {path}.')\n",
    "            logger.error(e)\n",
    "\n",
    "    def parent_3dtiles_from_children(self, tiles, bv_limit=None):\n",
    "        \"\"\"\n",
    "            Create parent Cesium 3D Tileset json files that point to of child\n",
    "            JSON files in the tile tree hierarchy. This method will take a list\n",
    "            of parent tiles and search the 3D tile directory for any children\n",
    "            tiles to create.\n",
    "            Parameters\n",
    "            ----------\n",
    "            tiles : list of morecantile.Tile\n",
    "                The list of parent tiles to create.\n",
    "        \"\"\"\n",
    "\n",
    "        tile_manager = self.tiles\n",
    "        config_manager = self.config\n",
    "\n",
    "        tileset_objs = []\n",
    "\n",
    "        # Make the next level of parent tiles\n",
    "        for parent_tile in tiles:\n",
    "            # Get the path to the parent tile\n",
    "            parent_path = tile_manager.path_from_tile(parent_tile, '3dtiles')\n",
    "            # Get just the base dir without the filename\n",
    "            parent_dir = os.path.dirname(parent_path)\n",
    "            # Get the filename of the parent tile, without the extension\n",
    "            parent_filename = os.path.basename(parent_path)\n",
    "            parent_filename = os.path.splitext(parent_filename)[0]\n",
    "            # Get the children paths for this parent tile\n",
    "            child_paths = tile_manager.get_child_paths(parent_tile, '3dtiles')\n",
    "            # Remove paths that do not exist\n",
    "            child_paths = tile_manager.remove_nonexistent_paths(child_paths)\n",
    "            # Get the parent bounding volume\n",
    "            parent_bv = self.bounding_region_for_tile(\n",
    "                parent_tile, limit_to=bv_limit)\n",
    "            # If the bounding region is outside t\n",
    "            # Get the version\n",
    "            version = config_manager.get('version')\n",
    "            # Get the geometric error\n",
    "            geometric_error = config_manager.get('geometricError')\n",
    "            # Create the parent tile\n",
    "            tileset_obj = TreeGenerator.parent_tile_from_children_json(\n",
    "                child_paths,\n",
    "                dir=parent_dir,\n",
    "                filename=parent_filename,\n",
    "                geometricError=geometric_error,\n",
    "                tilesetVersion=version,\n",
    "                boundingVolume=parent_bv\n",
    "            )\n",
    "            tileset_objs.append(tileset_obj)\n",
    "\n",
    "        return tileset_objs\n",
    "\n",
    "    def bounding_region_for_tile(self, tile, limit_to=None):\n",
    "        \"\"\"\n",
    "        For a morecantile.Tile object, return a BoundingVolumeRegion object\n",
    "        that represents the bounding region of the tile.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tile : morecantile.Tile\n",
    "            The tile object.\n",
    "        limit_to : list of float\n",
    "            Optional list of west, south, east, north coordinates to limit\n",
    "            the bounding region to.\n",
    "        Returns\n",
    "        -------\n",
    "        bv : BoundingVolumeRegion\n",
    "            The bounding region object.\n",
    "        \"\"\"\n",
    "        tms = self.tiles.tms\n",
    "        bounds = tms.bounds(tile)\n",
    "        bounds = gpd.GeoSeries(\n",
    "            box(bounds.left, bounds.bottom, bounds.right, bounds.top),\n",
    "            crs=tms.crs)\n",
    "        if limit_to is not None:\n",
    "            bounds_limitor = gpd.GeoSeries(\n",
    "                box(limit_to[0], limit_to[1], limit_to[2], limit_to[3]),\n",
    "                crs=tms.crs)\n",
    "            bounds = bounds.intersection(bounds_limitor)\n",
    "        bounds = bounds.to_crs(BoundingVolumeRegion.CESIUM_EPSG)\n",
    "        bounds = bounds.total_bounds\n",
    "\n",
    "        region_bv = {\n",
    "            'west': bounds[0], 'south': bounds[1],\n",
    "            'east': bounds[2], 'north': bounds[3],\n",
    "        }\n",
    "        return region_bv\n",
    "\n",
    "    def make_top_level_tileset(self):\n",
    "        \"\"\"\n",
    "        Create a top-level tileset.json file that sets all the min_z level\n",
    "        tiles as its children. This is needed to display the tiles in Cesium\n",
    "        when the min_z level has more than one tile.\n",
    "        Returns\n",
    "        -------\n",
    "        tileset : Tileset\n",
    "            The Cesium3DTileset object\n",
    "        \"\"\"\n",
    "\n",
    "        tile_manager = self.tiles\n",
    "        config_manager = self.config\n",
    "        min_z = config_manager.get_min_z()\n",
    "\n",
    "        # Make a parent tileset.json - this will combine the top level tiles if\n",
    "        # there are 2, otherwise it will just refer to the top level tile.\n",
    "        top_level_tiles = tile_manager.get_filenames_from_dir(\n",
    "            '3dtiles', z=min_z)\n",
    "        top_level_dir = tile_manager.get_base_dir('3dtiles')['path']\n",
    "\n",
    "        return TreeGenerator.parent_tile_from_children_json(\n",
    "            children=top_level_tiles,\n",
    "            dir=top_level_dir\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all batch sizes for workflow\n",
    "batch_size_staging=1,\n",
    "batch_size_rasterization=30,\n",
    "batch_size_3dtiles=20,\n",
    "batch_size_parent_3dtiles=500,\n",
    "batch_size_geotiffs=200,\n",
    "batch_size_web_tiles=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to batch files\n",
    "def make_batch(items, batch_size):\n",
    "    \"\"\"\n",
    "    Create batches of a given size from a list of items.\n",
    "    \"\"\"\n",
    "    return [items[i:i + batch_size] for i in range(0, len(items), batch_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the stager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stager = pdgstaging.TileStager(workflow_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage files in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staging files\n"
     ]
    }
   ],
   "source": [
    "# make paste statement at top of chunk because Scalable Computing Course noted that's good practice to recognize parsl app\n",
    "print('Staging files')\n",
    "\n",
    "@python_app\n",
    "def stage(paths, config, logging_dict=None):\n",
    "    \"\"\"\n",
    "    Stage a file (step 1)\n",
    "    \"\"\"\n",
    "    import pdgstaging\n",
    "    if logging_dict:\n",
    "        import logging.config\n",
    "        logging.config.dictConfig(logging_dict)\n",
    "    stager = pdgstaging.TileStager(config)\n",
    "    for path in paths:\n",
    "        stager.stage(path)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pdgviz')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b54da58c51b30b82a7fc0059a0ef455812aa5d7a05176ea08a9c6d431b69c979"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
