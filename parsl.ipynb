{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lake Change Sample Workflow with Parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# visualization\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "# PDG packages\n",
    "import pdgstaging\n",
    "import pdgraster\n",
    "import py3dtiles\n",
    "import viz_3dtiles\n",
    "#from viz_3dtiles import TreeGenerator, BoundingVolumeRegion\n",
    "#import pdgpy3dtiles\n",
    "#from StagedTo3DConverter import StagedTo3DConverter\n",
    "\n",
    "# logging and configuration\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import logging.config\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "# Parsl\n",
    "import parsl\n",
    "from parsl import python_app\n",
    "from parsl.config import Config\n",
    "#from parsl.channels import LocalChannel\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "#from parsl.executors.threads import ThreadPoolExecutor\n",
    "#from parsl.providers import LocalProvider\n",
    "from parsl.providers import KubernetesProvider\n",
    "from parsl.addresses import address_by_route\n",
    "from kubernetes import client, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_config = '/home/jcohen/lake_change_sample/ingmar-config.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point to the sample lake change dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path('/home/pdg/data/nitze_lake_change/data_sample_2022-09-09')\n",
    "subdirs = ['32607', '32608', '32609']\n",
    "filename = 'lake_change.gpkg'\n",
    "# to define each .gpkg file within each UTM subdir as a string representation with forward slashes, use as_posix() for each iteration\n",
    "# of base_dir + filename. The ** represents that any subdir string can be present between the base_dir and the filename, meaning I do not\n",
    "# think that we needed to create the object subdirs above\n",
    "input = [p.as_posix() for p in base_dir.glob('**/' + filename)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicitly define StagedTo3DConverter class & its methods rather than sourcing it in (I believe this needs to be debugged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging_config = '/home/jcohen/lake_change_sample/logging.json'\n",
    "\n",
    "class StagedTo3DConverter():\n",
    "    \"\"\"\n",
    "        Processes staged vector data into Cesium 3D tiles according to the\n",
    "        settings in a config file or dict. This class acts as the orchestrator\n",
    "        of the other viz-3dtiles classes, and coordinates the sending and\n",
    "        receiving of information between them.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config\n",
    "    ):\n",
    "        \"\"\"\n",
    "            Initialize the StagedTo3DConverter class.\n",
    "            Parameters\n",
    "            ----------\n",
    "            config : dict or str\n",
    "                A dictionary of configuration settings or a path to a config\n",
    "                JSON file. (See help(pdgstaging.ConfigManager))\n",
    "        \"\"\"\n",
    "\n",
    "        self.config = pdgstaging.ConfigManager(config)\n",
    "        self.tiles = pdgstaging.TilePathManager(\n",
    "            **self.config.get_path_manager_config())\n",
    "\n",
    "    def all_staged_to_3dtiles(\n",
    "        self\n",
    "    ):\n",
    "        \"\"\"\n",
    "            Process all staged vector tiles into 3D tiles.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the list of staged vector tiles\n",
    "        paths = self.tiles.get_filenames_from_dir('staged')\n",
    "        # Process each tile\n",
    "        for path in paths:\n",
    "            self.staged_to_3dtile(path)\n",
    "\n",
    "    def staged_to_3dtile(self, path):\n",
    "        \"\"\"\n",
    "            Convert a staged vector tile into a B3DM tile file and a matching\n",
    "            JSON tileset file.\n",
    "            Parameters\n",
    "            ----------\n",
    "            path : str\n",
    "                The path to the staged vector tile.\n",
    "            Returns\n",
    "            -------\n",
    "            tile, tileset : Cesium3DTile, Tileset\n",
    "                The Cesium3DTiles and Cesium3DTileset objects\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Get information about the tile from the path\n",
    "            tile = self.tiles.tile_from_path(path)\n",
    "            out_path = self.tiles.path_from_tile(tile, '3dtiles')\n",
    "\n",
    "            tile_bv = self.bounding_region_for_tile(tile)\n",
    "\n",
    "            # Get the filename of the tile WITHOUT the extension\n",
    "            tile_filename = os.path.splitext(os.path.basename(out_path))[0]\n",
    "            # Get the base of the path, without the filename\n",
    "            tile_dir = os.path.dirname(out_path) + os.path.sep\n",
    "\n",
    "            # Log the event\n",
    "            logger.info(\n",
    "                f'Creating 3dtile from {path} for tile {tile} to {out_path}.')\n",
    "\n",
    "            # Read in the staged vector tile\n",
    "            gdf = gpd.read_file(path)\n",
    "\n",
    "            # Check if the gdf is empty\n",
    "            if len(gdf) == 0:\n",
    "                logger.warning(\n",
    "                    f'Vector tile {path} is empty. 3D tile will not be'\n",
    "                    ' created.')\n",
    "                return\n",
    "\n",
    "            # Remove polygons with centroids that are outside the tile boundary\n",
    "            prop_cent_in_tile = self.config.polygon_prop(\n",
    "                'centroid_within_tile')\n",
    "            gdf = gdf[gdf[prop_cent_in_tile]]\n",
    "\n",
    "            # Check if deduplication should be performed\n",
    "            dedup_here = self.config.deduplicate_at('3dtiles')\n",
    "            dedup_method = self.config.get_deduplication_method()\n",
    "\n",
    "            # Deduplicate if required\n",
    "            if dedup_here and (dedup_method is not None):\n",
    "                dedup_config = self.config.get_deduplication_config(gdf)\n",
    "                dedup = dedup_method(gdf, **dedup_config)\n",
    "                gdf = dedup['keep']\n",
    "\n",
    "                # The tile could theoretically be empty after deduplication\n",
    "                if len(gdf) == 0:\n",
    "                    logger.warning(\n",
    "                        f'Vector tile {path} is empty after deduplication.'\n",
    "                        ' 3D Tile will not be created.')\n",
    "                    return\n",
    "\n",
    "            # Create & save the b3dm file\n",
    "            ces_tile, ces_tileset = TreeGenerator.leaf_tile_from_gdf(\n",
    "                gdf,\n",
    "                dir=tile_dir,\n",
    "                filename=tile_filename,\n",
    "                z=self.config.get('z_coord'),\n",
    "                geometricError=self.config.get('geometricError'),\n",
    "                tilesetVersion=self.config.get('version'),\n",
    "                boundingVolume=tile_bv\n",
    "            )\n",
    "\n",
    "            return ces_tile, ces_tileset\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f'Error creating 3D Tile from {path}.')\n",
    "            logger.error(e)\n",
    "\n",
    "    def parent_3dtiles_from_children(self, tiles, bv_limit=None):\n",
    "        \"\"\"\n",
    "            Create parent Cesium 3D Tileset json files that point to of child\n",
    "            JSON files in the tile tree hierarchy. This method will take a list\n",
    "            of parent tiles and search the 3D tile directory for any children\n",
    "            tiles to create.\n",
    "            Parameters\n",
    "            ----------\n",
    "            tiles : list of morecantile.Tile\n",
    "                The list of parent tiles to create.\n",
    "        \"\"\"\n",
    "\n",
    "        tile_manager = self.tiles\n",
    "        config_manager = self.config\n",
    "\n",
    "        tileset_objs = []\n",
    "\n",
    "        # Make the next level of parent tiles\n",
    "        for parent_tile in tiles:\n",
    "            # Get the path to the parent tile\n",
    "            parent_path = tile_manager.path_from_tile(parent_tile, '3dtiles')\n",
    "            # Get just the base dir without the filename\n",
    "            parent_dir = os.path.dirname(parent_path)\n",
    "            # Get the filename of the parent tile, without the extension\n",
    "            parent_filename = os.path.basename(parent_path)\n",
    "            parent_filename = os.path.splitext(parent_filename)[0]\n",
    "            # Get the children paths for this parent tile\n",
    "            child_paths = tile_manager.get_child_paths(parent_tile, '3dtiles')\n",
    "            # Remove paths that do not exist\n",
    "            child_paths = tile_manager.remove_nonexistent_paths(child_paths)\n",
    "            # Get the parent bounding volume\n",
    "            parent_bv = self.bounding_region_for_tile(\n",
    "                parent_tile, limit_to=bv_limit)\n",
    "            # If the bounding region is outside t\n",
    "            # Get the version\n",
    "            version = config_manager.get('version')\n",
    "            # Get the geometric error\n",
    "            geometric_error = config_manager.get('geometricError')\n",
    "            # Create the parent tile\n",
    "            tileset_obj = TreeGenerator.parent_tile_from_children_json(\n",
    "                child_paths,\n",
    "                dir=parent_dir,\n",
    "                filename=parent_filename,\n",
    "                geometricError=geometric_error,\n",
    "                tilesetVersion=version,\n",
    "                boundingVolume=parent_bv\n",
    "            )\n",
    "            tileset_objs.append(tileset_obj)\n",
    "\n",
    "        return tileset_objs\n",
    "\n",
    "    def bounding_region_for_tile(self, tile, limit_to=None):\n",
    "        \"\"\"\n",
    "        For a morecantile.Tile object, return a BoundingVolumeRegion object\n",
    "        that represents the bounding region of the tile.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tile : morecantile.Tile\n",
    "            The tile object.\n",
    "        limit_to : list of float\n",
    "            Optional list of west, south, east, north coordinates to limit\n",
    "            the bounding region to.\n",
    "        Returns\n",
    "        -------\n",
    "        bv : BoundingVolumeRegion\n",
    "            The bounding region object.\n",
    "        \"\"\"\n",
    "        tms = self.tiles.tms\n",
    "        bounds = tms.bounds(tile)\n",
    "        bounds = gpd.GeoSeries(\n",
    "            box(bounds.left, bounds.bottom, bounds.right, bounds.top),\n",
    "            crs=tms.crs)\n",
    "        if limit_to is not None:\n",
    "            bounds_limitor = gpd.GeoSeries(\n",
    "                box(limit_to[0], limit_to[1], limit_to[2], limit_to[3]),\n",
    "                crs=tms.crs)\n",
    "            bounds = bounds.intersection(bounds_limitor)\n",
    "        bounds = bounds.to_crs(BoundingVolumeRegion.CESIUM_EPSG)\n",
    "        bounds = bounds.total_bounds\n",
    "\n",
    "        region_bv = {\n",
    "            'west': bounds[0], 'south': bounds[1],\n",
    "            'east': bounds[2], 'north': bounds[3],\n",
    "        }\n",
    "        return region_bv\n",
    "\n",
    "    def make_top_level_tileset(self):\n",
    "        \"\"\"\n",
    "        Create a top-level tileset.json file that sets all the min_z level\n",
    "        tiles as its children. This is needed to display the tiles in Cesium\n",
    "        when the min_z level has more than one tile.\n",
    "        Returns\n",
    "        -------\n",
    "        tileset : Tileset\n",
    "            The Cesium3DTileset object\n",
    "        \"\"\"\n",
    "\n",
    "        tile_manager = self.tiles\n",
    "        config_manager = self.config\n",
    "        min_z = config_manager.get_min_z()\n",
    "\n",
    "        # Make a parent tileset.json - this will combine the top level tiles if\n",
    "        # there are 2, otherwise it will just refer to the top level tile.\n",
    "        top_level_tiles = tile_manager.get_filenames_from_dir(\n",
    "            '3dtiles', z=min_z)\n",
    "        top_level_dir = tile_manager.get_base_dir('3dtiles')['path']\n",
    "\n",
    "        return TreeGenerator.parent_tile_from_children_json(\n",
    "            children=top_level_tiles,\n",
    "            dir=top_level_dir\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to initialize Parsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parsl():\n",
    "    parsl.set_stream_logger()\n",
    "    #from parslexec import local_exec\n",
    "    #from parslexec import htex_kube\n",
    "\n",
    "    htex_kube = Config(\n",
    "        executors=[\n",
    "            HighThroughputExecutor(\n",
    "                label='kube-htex',\n",
    "                cores_per_worker=1,\n",
    "                max_workers=2,\n",
    "                worker_logdir_root='/',\n",
    "                # Address for the pod worker to connect back\n",
    "                # address=address_by_route(),\n",
    "                address='192.168.0.103',\n",
    "                # address_probe_timeout=3600,\n",
    "                worker_debug=True,\n",
    "                provider=KubernetesProvider(\n",
    "                    namespace=\"test\",\n",
    "\n",
    "                    # Docker image url to use for pods\n",
    "                    image='mbjones/python3-parsl:0.2',\n",
    "\n",
    "                    # Command to be run upon pod start, such as:\n",
    "                    # 'module load Anaconda; source activate parsl_env'.\n",
    "                    # or 'pip install parsl'\n",
    "                    #worker_init='echo \"Worker started...\"; lf=`find . -name \\'manager.log\\'` tail -n+1 -f ${lf}',\n",
    "                    worker_init='echo \"Worker started...\"',\n",
    "\n",
    "                    # The secret key to download the image\n",
    "                    # secret=\"YOUR_KUBE_SECRET\",\n",
    "\n",
    "                    # Should follow the Kubernetes naming rules\n",
    "                    pod_name='parsl-worker',\n",
    "\n",
    "                    nodes_per_block=1,\n",
    "                    init_blocks=2,\n",
    "                    min_blocks=1,\n",
    "                    # Maximum number of pods to scale up\n",
    "                    max_blocks=4,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    # parsl.load(local_exec)\n",
    "    parsl.load(htex_kube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to run workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pdg_workflow(\n",
    "    workflow_config,\n",
    "    logging_dict=None,\n",
    "    batch_size_staging=1,\n",
    "    batch_size_rasterization=30,\n",
    "    batch_size_3dtiles=20,\n",
    "    batch_size_parent_3dtiles=500,\n",
    "    batch_size_geotiffs=200,\n",
    "    batch_size_web_tiles=200\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the main PDG workflow\n",
    "    Parameters\n",
    "    ----------\n",
    "    workflow_config : dict\n",
    "        Configuration for the PDG staging workflow\n",
    "    logging_dict : dict\n",
    "        Logging configuration (to pass to the Parsl apps)\n",
    "    batch_size_staging : int\n",
    "        How many input files should be included in a single staging task? (each\n",
    "        task is run in parallel.) Default: 1\n",
    "    batch_size_rasterization : int\n",
    "        How many staged vector tile files should be included in a single\n",
    "        rasterization task? (each task is run in parallel.) Default: 30\n",
    "    batch_size_geotiffs : int\n",
    "        How many parent tiles should be included in a single composite geotiff\n",
    "        creating task? (each task is run in parallel.) Default: 200\n",
    "    batch_size_web_tiles : int\n",
    "        How many webtiles should be included in a single web tile creating\n",
    "        task? (each task is run in parallel.) Default: 200\n",
    "    \"\"\"\n",
    "\n",
    "    stager = pdgstaging.TileStager(workflow_config)\n",
    "    tiles3dmaker = StagedTo3DConverter(workflow_config)\n",
    "    rasterizer = pdgraster.RasterTiler(workflow_config)\n",
    "    tile_manager = stager.tiles\n",
    "    config_manager = stager.config\n",
    "    min_z = config_manager.get_min_z()\n",
    "    max_z = config_manager.get_max_z()\n",
    "    parent_zs = range(max_z - 1, min_z - 1, -1)\n",
    "\n",
    "    # ================================================================\n",
    "    # Start the workflow\n",
    "\n",
    "    overall_start = datetime.now()\n",
    "\n",
    "    # ================================================================\n",
    "    # STEP 1: Stage all inputs\n",
    "\n",
    "    # Get all paths to input files and create batches of paths\n",
    "    input_paths = stager.tiles.get_filenames_from_dir(input) # I changed `input` string to an input object that represents path to data sample on server\n",
    "    input_batches = make_batch(input_paths, batch_size_staging)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # Stage all the input files (each batch in parallel)\n",
    "    app_futures = []\n",
    "    for batch in input_batches:\n",
    "        app_future = stage(batch, workflow_config, logging_dict)\n",
    "        app_futures.append(app_future)\n",
    "\n",
    "    # Don't continue to step 2 until all files have been staged\n",
    "    [a.result() for a in app_futures]\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    logging.info(f'Total time to stage {len(input_paths)} files: '\n",
    "                 f'{end_time - start_time}')\n",
    "\n",
    "    # =================================================================================\n",
    "    # STEP 2: Deduplicate & rasterize all staged tiles (only highest z-level)\n",
    "\n",
    "    # Get paths to all the newly staged tiles\n",
    "    staged_paths = stager.tiles.get_filenames_from_dir('staged')\n",
    "    staged_batches = make_batch(staged_paths, batch_size_rasterization)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    app_futures = []\n",
    "    for batch in staged_batches:\n",
    "        app_future = rasterize(batch, workflow_config, logging_dict)\n",
    "        app_futures.append(app_future)\n",
    "\n",
    "    # Don't continue to step 3 until all tiles have been rasterized\n",
    "    [a.result() for a in app_futures]\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    logging.info(f'⏰ Total time to rasterize {len(staged_paths)} tiles: '\n",
    "                 f'{end_time - start_time}')\n",
    "\n",
    "    # =================================================================================\n",
    "    # STEP 3: Create parent geotiffs for all z-levels (except highest)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # Can't start lower z-level until higher z-level is complete.\n",
    "    for z in parent_zs:\n",
    "\n",
    "        # Determine which tiles we need to make for the next z-level based on the\n",
    "        # path names of the files just created\n",
    "        child_paths = tile_manager.get_filenames_from_dir('geotiff', z=z + 1)\n",
    "        parent_tiles = set()\n",
    "        for child_path in child_paths:\n",
    "            parent_tile = tile_manager.get_parent_tile(child_path)\n",
    "            parent_tiles.add(parent_tile)\n",
    "        parent_tiles = list(parent_tiles)\n",
    "\n",
    "        # Break all parent tiles at level z into batches\n",
    "        parent_tile_batches = make_batch(parent_tiles, batch_size_geotiffs)\n",
    "\n",
    "        # Make the next level of parent tiles\n",
    "        app_futures = []\n",
    "        for parent_tile_batch in parent_tile_batches:\n",
    "            app_future = create_composite_geotiffs(\n",
    "                parent_tile_batch, workflow_config, logging_dict)\n",
    "            app_futures.append(app_future)\n",
    "\n",
    "        # Don't start the next z-level, and don't move to step 4, until the\n",
    "        # current z-level is complete\n",
    "        [a.result() for a in app_futures]\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    logging.info(f'⏰ Total time to create parent geotiffs: '\n",
    "                 f'{end_time - start_time}')\n",
    "\n",
    "    # =================================================================================\n",
    "    # STEP 4: Create web tiles from geotiffs\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # Update ranges\n",
    "    rasterizer.update_ranges()\n",
    "\n",
    "    # Process web tiles in batches\n",
    "    geotiff_paths = tile_manager.get_filenames_from_dir('geotiff')\n",
    "    geotiff_batches = make_batch(geotiff_paths, batch_size_web_tiles)\n",
    "\n",
    "    app_futures = []\n",
    "    for batch in geotiff_batches:\n",
    "        app_future = create_web_tiles(batch, workflow_config, logging_dict)\n",
    "        app_futures.append(app_future)\n",
    "\n",
    "    # Don't record end time until all web tiles have been created\n",
    "    [a.result() for a in app_futures]\n",
    "\n",
    "    end_time = datetime.now()\n",
    "\n",
    "    logging.info(f'⏰ Total time to create web tiles: '\n",
    "                 f'{end_time - start_time}')\n",
    "\n",
    "    # =================================================================================\n",
    "    # STEP 5: Deduplicate & make leaf 3D tiles all staged tiles (only highest\n",
    "    # z-level).\n",
    "    # TODO: COMBINE WITH STEP 2, so we only read in and deduplicate\n",
    "    # each staged file once.\n",
    "\n",
    "    # Get paths to all the newly staged tiles\n",
    "    staged_paths = stager.tiles.get_filenames_from_dir('staged')\n",
    "    staged_batches = make_batch(staged_paths, batch_size_3dtiles)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    app_futures = []\n",
    "    for batch in staged_batches:\n",
    "        app_future = create_leaf_3dtiles(batch, workflow_config, logging_dict)\n",
    "        app_futures.append(app_future)\n",
    "\n",
    "    # Don't continue to step 6 until all max-zoom level 3d tilesets have been\n",
    "    # created\n",
    "    [a.result() for a in app_futures]\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    logging.info(f'⏰ Total time to create {len(staged_paths)} 3d tiles: '\n",
    "                 f'{end_time - start_time}')\n",
    "\n",
    "    # =================================================================================\n",
    "    # STEP 6: Create parent cesium 3d tilesets for all z-levels (except highest)\n",
    "    # TODO: COMBINE WITH STEP 3\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # For tiles in max-z-level, get the total bounds for all the tiles. We will\n",
    "    # limit parent tileset bounding volumes to this total bounds.\n",
    "    # convert the paths to tiles\n",
    "    max_z_tiles = [tile_manager.tile_from_path(path) for path in staged_paths]\n",
    "    # get the total bounds for all the tiles\n",
    "    max_z_bounds = [tile_manager.get_bounding_box(\n",
    "        tile) for tile in max_z_tiles]\n",
    "    # get the total bounds for all the tiles\n",
    "    polygons = [box(bounds['left'],\n",
    "                    bounds['bottom'],\n",
    "                    bounds['right'],\n",
    "                    bounds['top']) for bounds in max_z_bounds]\n",
    "    max_z_bounds = gpd.GeoSeries(polygons, crs=tile_manager.tms.crs)\n",
    "\n",
    "    bound_volume_limit = max_z_bounds.total_bounds\n",
    "\n",
    "    # Can't start lower z-level until higher z-level is complete.\n",
    "    for z in parent_zs:\n",
    "\n",
    "        # Determine which tiles we need to make for the next z-level based on the\n",
    "        # path names of the files just created\n",
    "        all_child_paths = tiles3dmaker.tiles.get_filenames_from_dir(\n",
    "            '3dtiles', z=z + 1)\n",
    "        parent_tiles = set()\n",
    "        for child_path in all_child_paths:\n",
    "            parent_tile = tile_manager.get_parent_tile(child_path)\n",
    "            parent_tiles.add(parent_tile)\n",
    "        parent_tiles = list(parent_tiles)\n",
    "\n",
    "        # Break all parent tiles at level z into batches\n",
    "        parent_tile_batches = make_batch(\n",
    "            parent_tiles, batch_size_parent_3dtiles)\n",
    "\n",
    "        # Make the next level of parent tiles\n",
    "        app_futures = []\n",
    "        for parent_tile_batch in parent_tile_batches:\n",
    "            app_future = create_parent_3dtiles(\n",
    "                parent_tile_batch,\n",
    "                workflow_config,\n",
    "                bound_volume_limit,\n",
    "                logging_dict)\n",
    "            app_futures.append(app_future)\n",
    "\n",
    "        # Don't start the next z-level until the current z-level is complete\n",
    "        [a.result() for a in app_futures]\n",
    "\n",
    "    # Make a top-level tileset.json file - essential when the min_z level\n",
    "    # comprises 2+ tiles, useful in any case so that the path to use in cesium\n",
    "    # is consistently path/to/3dtiles/dir/tileset.json\n",
    "    tiles3dmaker.make_top_level_tileset()\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    logging.info(f'⏰ Total time to create parent 3d tiles: '\n",
    "                 f'{end_time - start_time}')\n",
    "\n",
    "    # ================================================================\n",
    "    # End the workflow\n",
    "\n",
    "    overall_end = datetime.now()\n",
    "    total_time = overall_end - overall_start\n",
    "    message = f'⏰ Total time to complete workflow: {total_time}'\n",
    "    logging.info(message)\n",
    "    print(message)\n",
    "\n",
    "\n",
    "@python_app\n",
    "def stage(paths, config, logging_dict=None):\n",
    "    \"\"\"\n",
    "    Stage a file (step 1)\n",
    "    \"\"\"\n",
    "    import pdgstaging\n",
    "    if logging_dict:\n",
    "        import logging.config\n",
    "        logging.config.dictConfig(logging_dict)\n",
    "    stager = pdgstaging.TileStager(config)\n",
    "    for path in paths:\n",
    "        stager.stage(path)\n",
    "    return True\n",
    "\n",
    "\n",
    "@python_app\n",
    "def rasterize(staged_paths, config, logging_dict=None):\n",
    "    \"\"\"\n",
    "    Rasterize a batch of vector files (step 2)\n",
    "    \"\"\"\n",
    "    import pdgraster\n",
    "    if logging_dict:\n",
    "        import logging.config\n",
    "        logging.config.dictConfig(logging_dict)\n",
    "    rasterizer = pdgraster.RasterTiler(config)\n",
    "    return rasterizer.rasterize_vectors(staged_paths, make_parents=False)\n",
    "\n",
    "\n",
    "@python_app\n",
    "def create_composite_geotiffs(tiles, config, logging_dict=None):\n",
    "    \"\"\"\n",
    "    Make composite geotiffs (step 3)\n",
    "    \"\"\"\n",
    "    import pdgraster\n",
    "    if logging_dict:\n",
    "        import logging.config\n",
    "        logging.config.dictConfig(logging_dict)\n",
    "    rasterizer = pdgraster.RasterTiler(config)\n",
    "    return rasterizer.parent_geotiffs_from_children(tiles, recursive=False)\n",
    "\n",
    "\n",
    "@python_app\n",
    "def create_leaf_3dtiles(staged_paths, config, logging_dict=None):\n",
    "    \"\"\"\n",
    "    Create a batch of leaf 3d tiles from staged vector tiles\n",
    "    \"\"\"\n",
    "    from pdg_workflow import StagedTo3DConverter\n",
    "    if logging_dict:\n",
    "        import logging.config\n",
    "        logging.config.dictConfig(logging_dict)\n",
    "    converter3d = StagedTo3DConverter(config)\n",
    "    tilesets = []\n",
    "    for path in staged_paths:\n",
    "        ces_tile, ces_tileset = converter3d.staged_to_3dtile(path)\n",
    "        tilesets.append(ces_tileset)\n",
    "    return tilesets\n",
    "\n",
    "\n",
    "@python_app\n",
    "def create_parent_3dtiles(tiles, config, limit_bv_to=None, logging_dict=None):\n",
    "    \"\"\"\n",
    "    Create a batch of cesium 3d tileset parent files that point to child\n",
    "    tilesets\n",
    "    \"\"\"\n",
    "    from pdg_workflow import StagedTo3DConverter\n",
    "    if logging_dict:\n",
    "        import logging.config\n",
    "        logging.config.dictConfig(logging_dict)\n",
    "    converter3d = StagedTo3DConverter(config)\n",
    "    return converter3d.parent_3dtiles_from_children(tiles, limit_bv_to)\n",
    "\n",
    "\n",
    "# Create a batch of webtiles from geotiffs (step 4)\n",
    "@python_app\n",
    "def create_web_tiles(geotiff_paths, config, logging_dict=None):\n",
    "    \"\"\"\n",
    "    Create a batch of webtiles from geotiffs (step 4)\n",
    "    \"\"\"\n",
    "    import pdgraster\n",
    "    if logging_dict:\n",
    "        import logging.config\n",
    "        logging.config.dictConfig(logging_dict)\n",
    "    rasterizer = pdgraster.RasterTiler(config)\n",
    "    return rasterizer.webtiles_from_geotiffs(\n",
    "        geotiff_paths, update_ranges=False)\n",
    "\n",
    "\n",
    "def make_batch(items, batch_size):\n",
    "    \"\"\"\n",
    "    Create batches of a given size from a list of items.\n",
    "    \"\"\"\n",
    "    return [items[i:i + batch_size] for i in range(0, len(items), batch_size)]\n",
    "\n",
    "\n",
    "def setup_logging(log_json_file):\n",
    "    \"\"\"\n",
    "    Setup logging configuration\n",
    "    \"\"\"\n",
    "    with open(log_json_file, 'r') as f:\n",
    "        logging_dict = json.load(f)\n",
    "    logging.config.dictConfig(logging_dict)\n",
    "    return logging_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the parsl workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Run the PDG visualization workflow.')\n",
    "    parser.add_argument('-c', '--config',\n",
    "                        help='Path to the pdg-viz configuration JSON file.',\n",
    "                        default='config.json',\n",
    "                        type=str)\n",
    "    parser.add_argument('-l', '--logging',\n",
    "                        help='Path to the logging configuration JSON file.',\n",
    "                        default='logging.json',\n",
    "                        type=str)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    logging_dict = setup_logging(args.logging)\n",
    "    init_parsl()\n",
    "    run_pdg_workflow(args.config, logging_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pdgviz')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b54da58c51b30b82a7fc0059a0ef455812aa5d7a05176ea08a9c6d431b69c979"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
