{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import logging\n",
    "import logging.config\n",
    "import json\n",
    "\n",
    "# import parallelization packages\n",
    "import parsl\n",
    "from parsl import python_app\n",
    "from parsl.config import Config\n",
    "from parsl.channels import LocalChannel\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.providers import LocalProvider\n",
    "\n",
    "# PDG packages\n",
    "import pdgstaging # used within the class we create called `StagedTo3DConverter`\n",
    "import pdgraster\n",
    "import py3dtiles\n",
    "\n",
    "# note: do not need to import parsl because we do that in the function we create, init_parsl() ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track events that happen as software is executed, helpful for debugging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a class that orchestrates viz-3dtiles classes and communicates information between them\n",
    "\n",
    "- `__init__` is used to create an object from a class, it is only used within classes\n",
    "- using `__init__` is the \"constructor method\" that is derived from C++ and Java\n",
    "- functions defined within a class are called methods\n",
    "- using `__init__` results in the methods being automatically applied to any object that is created of the class `StagedTo3DConverter`\n",
    "- in summary, this means that when an object of class `StagedTo3DConverter` is created, the configuration .json file is automatically applied to that object\n",
    "- the methods that are defined after this initiation happens so not automatically occur, they must be deliberately applied\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StagedTo3DConverter():\n",
    "    \"\"\"\n",
    "        Processes staged vector data into Cesium 3D tiles according to the\n",
    "        settings in a config file or dict. This class acts as the orchestrator\n",
    "        of the other viz-3dtiles classes, and coordinates the sending and\n",
    "        receiving of information between them.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config\n",
    "    ):\n",
    "        \"\"\"\n",
    "            Automatically initialize the StagedTo3DConverter class by appying the configuration when an object of that class is created.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            self : need to explicitly state this parameter to pass any newly created object of class StagedTo3DConverter to the other paraneter (config)\n",
    "                this is a python syntax requirement in order for the object to persist of this class\n",
    "\n",
    "            config : dict or str\n",
    "                A dictionary of configuration settings or a path to a config\n",
    "                JSON file. (See help(pdgstaging.ConfigManager))\n",
    "\n",
    "            Notes\n",
    "            ----------\n",
    "            - this function does not do the staging or tiling steps\n",
    "        \"\"\"\n",
    "\n",
    "        self.config = pdgstaging.ConfigManager(config)\n",
    "        self.tiles = pdgstaging.TilePathManager(\n",
    "            **self.config.get_path_manager_config())\n",
    "\n",
    "    def all_staged_to_3dtiles(\n",
    "        self\n",
    "    ):\n",
    "        \"\"\"\n",
    "            Process all staged vector tiles into 3D tiles. This is simply a loop that iterates the function staged_to_rdtile() over all files in the staged directory.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the list of staged vector tiles\n",
    "        paths = self.tiles.get_filenames_from_dir('staged')\n",
    "        # Process each tile\n",
    "        for path in paths:\n",
    "            self.staged_to_3dtile(path)\n",
    "\n",
    "    def staged_to_3dtile(self, path):\n",
    "        \"\"\"\n",
    "            Convert a staged vector tile into a B3DM tile file and a matching\n",
    "            JSON tileset file.\n",
    "            - the B3DM tile is applied to the PDG portal for visualization purposes\n",
    "            - the JSON serves as the metadata for that tile\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            path : str\n",
    "                The path to the staged vector tile.\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            tile, tileset : Cesium3DTile, Tileset\n",
    "                The Cesium3DTiles and Cesium3DTileset objects\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            \n",
    "            # Get information about the tile from the path\n",
    "            tile = self.tiles.tile_from_path(path)\n",
    "            out_path = self.tiles.path_from_tile(tile, '3dtiles')\n",
    "\n",
    "            tile_bv = self.bounding_region_for_tile(tile) # bv = bounding volumne\n",
    "\n",
    "            # Get the filename of the tile WITHOUT the extension\n",
    "            tile_filename = os.path.splitext(os.path.basename(out_path))[0]\n",
    "            # Get the base of the path, without the filename\n",
    "            tile_dir = os.path.dirname(out_path) + os.path.sep\n",
    "\n",
    "            # Log the event\n",
    "            logger.info(\n",
    "                f'Creating 3dtile from {path} for tile {tile} to {out_path}.')\n",
    "\n",
    "            # Read in the staged vector tile\n",
    "            gdf = gpd.read_file(path)\n",
    "\n",
    "            # Summary of following steps:\n",
    "            # Now that we have the path to the staged vector tile esptablished and logged, \n",
    "            # the following checks are executed on each staged vector tile:\n",
    "            # 1. check if the tile has any data to start with\n",
    "            # 2. check if the centroid of the polygons within the tile are within the tile boundaries, remove if not\n",
    "            # 3. check if polygons within the tile overlap, deduplicate them if they do\n",
    "            # 4. check if the tile has any data left if deduplication was executed\n",
    "            # 5. if there were errors in the above steps, log that for debugging\n",
    "\n",
    "            \n",
    "            # Check if the gdf is empty\n",
    "            if len(gdf) == 0:\n",
    "                logger.warning(\n",
    "                    f'Vector tile {path} is empty. 3D tile will not be'\n",
    "                    ' created.')\n",
    "                return\n",
    "\n",
    "            # Remove polygons with centroids that are outside the tile boundary\n",
    "            prop_cent_in_tile = self.config.polygon_prop(\n",
    "                'centroid_within_tile')\n",
    "            gdf = gdf[gdf[prop_cent_in_tile]]\n",
    "\n",
    "            # Check if deduplication should be performed\n",
    "            dedup_here = self.config.deduplicate_at('3dtiles')\n",
    "            dedup_method = self.config.get_deduplication_method()\n",
    "\n",
    "            # Deduplicate if required\n",
    "            if dedup_here and (dedup_method is not None):\n",
    "                dedup_config = self.config.get_deduplication_config(gdf)\n",
    "                dedup = dedup_method(gdf, **dedup_config)\n",
    "                gdf = dedup['keep']\n",
    "\n",
    "                # The tile could theoretically be empty after deduplication\n",
    "                if len(gdf) == 0:\n",
    "                    logger.warning(\n",
    "                        f'Vector tile {path} is empty after deduplication.'\n",
    "                        ' 3D Tile will not be created.')\n",
    "                    return\n",
    "\n",
    "            # Create & save the b3dm file\n",
    "            ces_tile, ces_tileset = TreeGenerator.leaf_tile_from_gdf(\n",
    "                gdf,\n",
    "                dir=tile_dir,\n",
    "                filename=tile_filename,\n",
    "                z=self.config.get('z_coord'),\n",
    "                geometricError=self.config.get('geometricError'),\n",
    "                tilesetVersion=self.config.get('version'),\n",
    "                boundingVolume=tile_bv\n",
    "            )\n",
    "\n",
    "            return ces_tile, ces_tileset\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f'Error creating 3D Tile from {path}.')\n",
    "            logger.error(e)\n",
    "\n",
    "    def parent_3dtiles_from_children(self, tiles, bv_limit=None):\n",
    "        \"\"\"\n",
    "            Create parent Cesium 3D Tileset json files that point to\n",
    "            of child JSON files in the tile tree hierarchy.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            tiles : list of morecantile.Tile\n",
    "                The list of tiles to create parent tiles for.\n",
    "        \"\"\"\n",
    "\n",
    "        tile_manager = self.tiles\n",
    "        config_manager = self.config\n",
    "\n",
    "        tileset_objs = []\n",
    "\n",
    "        # Make the next level of parent tiles\n",
    "        for parent_tile in tiles:\n",
    "            # Get the path to the parent tile\n",
    "            parent_path = tile_manager.path_from_tile(parent_tile, '3dtiles')\n",
    "            # Get just the base dir without the filename\n",
    "            parent_dir = os.path.dirname(parent_path)\n",
    "            # Get the filename of the parent tile, without the extension\n",
    "            parent_filename = os.path.basename(parent_path)\n",
    "            parent_filename = os.path.splitext(parent_filename)[0]\n",
    "            # Get the children paths for this parent tile\n",
    "            child_paths = tile_manager.get_child_paths(parent_tile, '3dtiles')\n",
    "            # Remove paths that do not exist\n",
    "            child_paths = tile_manager.remove_nonexistent_paths(child_paths)\n",
    "            # Get the parent bounding volume\n",
    "            parent_bv = self.bounding_region_for_tile(\n",
    "                parent_tile, limit_to=bv_limit)\n",
    "            # If the bounding region is outside t\n",
    "            # Get the version\n",
    "            version = config_manager.get('version')\n",
    "            # Get the geometric error\n",
    "            geometric_error = config_manager.get('geometricError')\n",
    "            # Create the parent tile\n",
    "            tileset_obj = TreeGenerator.parent_tile_from_children_json(\n",
    "                child_paths,\n",
    "                dir=parent_dir,\n",
    "                filename=parent_filename,\n",
    "                geometricError=geometric_error,\n",
    "                tilesetVersion=version,\n",
    "                boundingVolume=parent_bv\n",
    "            )\n",
    "            tileset_objs.append(tileset_obj)\n",
    "\n",
    "        return tileset_objs\n",
    "\n",
    "    def bounding_region_for_tile(self, tile, limit_to=None):\n",
    "        \"\"\"\n",
    "        For a morecantile.Tile object, return a BoundingVolumeRegion object\n",
    "        that represents the bounding region of the tile.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tile : morecantile.Tile\n",
    "            The tile object.\n",
    "        limit_to : list of float\n",
    "            Optional list of west, south, east, north coordinates to limit\n",
    "            the bounding region to.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bv : BoundingVolumeRegion\n",
    "            The bounding region object.\n",
    "        \"\"\"\n",
    "        tms = self.tiles.tms\n",
    "        bounds = tms.bounds(tile)\n",
    "        bounds = gpd.GeoSeries(\n",
    "            box(bounds.left, bounds.bottom, bounds.right, bounds.top),\n",
    "            crs=tms.crs)\n",
    "        if limit_to is not None:\n",
    "            bounds_limitor = gpd.GeoSeries(\n",
    "                box(limit_to[0], limit_to[1], limit_to[2], limit_to[3]),\n",
    "                crs=tms.crs)\n",
    "            bounds = bounds.intersection(bounds_limitor)\n",
    "        bounds = bounds.to_crs(BoundingVolumeRegion.CESIUM_EPSG)\n",
    "        bounds = bounds.total_bounds\n",
    "\n",
    "        region_bv = {\n",
    "            'west': bounds[0], 'south': bounds[1],\n",
    "            'east': bounds[2], 'north': bounds[3],\n",
    "        }\n",
    "        return region_bv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to configure parsl\n",
    "\n",
    "Use this approach, setting up a `HighThroughputExecutor`, instead of the `kubernetes` approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parsl():\n",
    "    import parsl\n",
    "    from parsl.config import Config\n",
    "    from parsl.channels import LocalChannel\n",
    "    from parsl.executors import HighThroughputExecutor\n",
    "    from parsl.providers import LocalProvider\n",
    "    # bash command to activate pdgviz virtual environment, this will be run \n",
    "    activate_conda = 'source /home/jcohen/.bashrc; conda activate pdgviz'\n",
    "    htex_local = Config(\n",
    "        executors=[\n",
    "            HighThroughputExecutor(\n",
    "                # label this executor instance as \"htex_local\"\n",
    "                label=\"htex_local\",\n",
    "                # do not enable worker debug logging\n",
    "                worker_debug=False,\n",
    "                cores_per_worker=2,\n",
    "                # Why is the max workers only 2?\n",
    "                max_workers=2,\n",
    "                # enables user to run locally on machine, as opposed to a slurm scheduler\n",
    "                provider=LocalProvider(\n",
    "                    channel=LocalChannel(),\n",
    "                    init_blocks=1,\n",
    "                    max_blocks=10,\n",
    "                    # run the bash command to activate pdgviz virtual environment\n",
    "                    worker_init=activate_conda\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    # shut down the executor and clear the parsl engine\n",
    "    parsl.clear()\n",
    "    parsl.load(htex_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up parsl app to create leaf 3d Cesium tiles in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining function to create leaf 3d Cesium tiles from staged tiles in parallel.\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining function to create leaf 3d Cesium tiles from staged tiles in parallel.\")\n",
    "\n",
    "@python_app\n",
    "def create_leaf_3dtiles(staged_paths, config, logging_dict=None):\n",
    "    \"\"\"\n",
    "    Create a batch of leaf 3d tiles from staged vector tiles\n",
    "    \"\"\"\n",
    "    # do i need to download this package still? Robyn said she has issues sourcing it, which is why we define it above as a method in the same script as this chunk, so I comment the following import out for now\n",
    "    #from pdg_workflow import StagedTo3DConverter\n",
    "    if logging_dict:\n",
    "        import logging.config\n",
    "        logging.config.dictConfig(logging_dict)\n",
    "    converter3d = StagedTo3DConverter(config)\n",
    "    tilesets = []\n",
    "    for path in staged_paths:\n",
    "        try: # the syntax that follows is confusing, it reminds me of the fig, ax syntax\n",
    "            ces_tile, ces_tileset = converter3d.staged_to_3dtile(path) # the fact that we call this func here supports my understanding that the methods defined within stagedTo3DConverter are not automatically executed (except for the first one with __init__) until called, after the obj of that class is created\n",
    "            tilesets.append(ces_tileset)\n",
    "        except Exception as e:\n",
    "            logging.error(f'Error creating 3d tile from {path}')\n",
    "            logging.error(e)\n",
    "    return tilesets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up parsl app to create parent 3d Cesium tiles in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining function to create parent 3d Cesium tiles in parallel.\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining function to create parent 3d Cesium tiles in parallel.\")\n",
    "\n",
    "@python_app\n",
    "def create_parent_3dtiles(tiles, config, limit_bv_to=None, logging_dict=None):\n",
    "    \"\"\"\n",
    "    Create a batch of cesium 3d tileset parent files that point to child\n",
    "    tilesets\n",
    "    \"\"\"\n",
    "    #from pdg_workflow import StagedTo3DConverter\n",
    "    if logging_dict:\n",
    "        import logging.config\n",
    "        logging.config.dictConfig(logging_dict)\n",
    "    logging.info(f'Creating parent 3d tiles for {len(tiles)} tiles')\n",
    "    converter3d = StagedTo3DConverter(config)\n",
    "    return converter3d.parent_3dtiles_from_children(tiles, limit_bv_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to batch the input data into the user's specified size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(items, batch_size):\n",
    "    \"\"\"\n",
    "    Create batches of a given size from a list of items.\n",
    "    \"\"\"\n",
    "    return [items[i:i + batch_size] for i in range(0, len(items), batch_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup logging configuration for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(log_json_file):\n",
    "    \"\"\"\n",
    "    Setup logging configuration\n",
    "    \"\"\"\n",
    "    with open(log_json_file, 'r') as f:\n",
    "        logging_dict = json.load(f)\n",
    "    logging.config.dictConfig(logging_dict)\n",
    "    return logging_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define objects that will be used throughout parallelization:\n",
    "- filepath to configuration .json file\n",
    "- filepath for logging for debugging\n",
    "- batch sizes for:\n",
    "    - staging\n",
    "    - rasterization\n",
    "    - creating 3d tiles (both parents and leafs)\n",
    "    - creating geotiffs\n",
    "    - web tiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_config = '/home/jcohen/lake_change_sample/ingmar-config__updated.json'\n",
    "logging_config = '/home/jcohen/lake_change_sample/logging.json'\n",
    "batch_size_staging = 1\n",
    "batch_size_rasterization = 30\n",
    "batch_size_3dtiles = 20 # leaf tiles? higher resolution, more zoomed in, which is why we process fewer of them in a batch relative to the parent tiles\n",
    "batch_size_parent_3dtiles = 500\n",
    "batch_size_geotiffs = 200\n",
    "batch_size_web_tiles = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we created this function in this script earlier, it reads in the logging configuration file\n",
    "logging_dict = setup_logging(logging_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "1. are the 3dtiles referenced in the object batch_size_rdtiles the leaf tiles? I assumed cause the other object specifies they are parent 3d tiles \n",
    "2. difference between 3d tiles and web tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the following:\n",
    "- stager (didnt we already stage the files?)\n",
    "- rasterizer (didnt we already rasterize the files?)\n",
    "- 3d tiler\n",
    "- tile manager (??)\n",
    "- config manager (??)\n",
    "- minimum zoom level\n",
    "- maximum zoom level\n",
    "- range of zoom levels (??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stager = pdgstaging.TileStager(workflow_config)\n",
    "tiles3dmaker = StagedTo3DConverter(workflow_config)\n",
    "rasterizer = pdgraster.RasterTiler(workflow_config)\n",
    "tile_manager = stager.tiles\n",
    "config_manager = stager.config\n",
    "min_z = config_manager.get_min_z() # parent tiles\n",
    "max_z = config_manager.get_max_z() # child tiles\n",
    "parent_zs = range(max_z - 1, min_z - 1, -1) # example: (11-1), (0-1), by -1 = 10 thru -1 by -1 = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get paths for staged tiles in the staged directory, then batch them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staged_paths = stager.tiles.get_filenames_from_dir('staged')\n",
    "staged_batches = make_batch(staged_paths, batch_size_3dtiles)\n",
    "\n",
    "for batch in staged_batches:\n",
    "    create_leaf_3dtiles(batch, workflow_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pdgviz': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b54da58c51b30b82a7fc0059a0ef455812aa5d7a05176ea08a9c6d431b69c979"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
